name: Hourly Kayak Data Collection

on:
  schedule:
    # Run every hour at the top of the hour
    - cron: '0 * * * *'
  workflow_dispatch: # Allow manual triggering
  push:
    branches: [ main ]  # Also run on pushes to main for testing

jobs:
  collect-data:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create data directories
      run: |
        mkdir -p kayak_forecast_data/river_data
        mkdir -p kayak_forecast_data/weather_data  
        mkdir -p kayak_forecast_data/combined_data
    
    - name: Run data collection
      run: |
        python data_export.py
    
    - name: Configure Git
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
    
    - name: Check for changes
      id: verify-changed-files
      run: |
        if [ -n "$(git status --porcelain)" ]; then
          echo "changed=true" >> $GITHUB_OUTPUT
        else
          echo "changed=false" >> $GITHUB_OUTPUT
        fi
    
    - name: Commit and push changes
      if: steps.verify-changed-files.outputs.changed == 'true'
      run: |
        echo "Changes detected, committing files..."
        git add kayak_forecast_data/
        git add -A
        git status
        git commit -m "Automated data update - $(date '+%Y-%m-%d %H:%M:%S UTC')"
        git push
    
    - name: No changes detected
      if: steps.verify-changed-files.outputs.changed == 'false'
      run: |
        echo "No changes detected in data files."
    
    - name: Upload data as artifact
      uses: actions/upload-artifact@v3
      with:
        name: kayak-forecast-data-${{ github.run_number }}
        path: kayak_forecast_data/
        retention-days: 7
    
    - name: Summary
      run: |
        echo "## ðŸ“Š Data Collection Summary" >> $GITHUB_STEP_SUMMARY
        echo "- **Timestamp:** $(date '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
        echo "- **Status:** âœ… Completed successfully" >> $GITHUB_STEP_SUMMARY
        
        if [ -f kayak_forecast_data/river_data/historical_hourly_data.csv ]; then
          RIVER_ROWS=$(wc -l < kayak_forecast_data/river_data/historical_hourly_data.csv)
          echo "- **River Data Rows:** $RIVER_ROWS" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -f kayak_forecast_data/combined_data/optimal_windows.csv ]; then
          OPTIMAL_WINDOWS=$(tail -n +2 kayak_forecast_data/combined_data/optimal_windows.csv | wc -l)
          echo "- **Optimal Windows Found:** $OPTIMAL_WINDOWS" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "- **Data Files Created:**" >> $GITHUB_STEP_SUMMARY
        find kayak_forecast_data -name "*.csv" -type f | sed 's/^/  - /' >> $GITHUB_STEP_SUMMARY

# Optional: Add a manual cleanup job
  cleanup-old-runs:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' # Only run on scheduled executions
    needs: collect-data
    
    steps:
    - name: Delete old workflow runs
      uses: Mattraks/delete-workflow-runs@v2
      with:
        token: ${{ github.token }}
        repository: ${{ github.repository }}
        retain_days: 7
        keep_minimum_runs: 10
